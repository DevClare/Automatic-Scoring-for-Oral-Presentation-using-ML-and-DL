This project implements machine learning (SVM, Random Forest) and deep learning (CNN, YOLOv8) approaches to automatically score oral presentations using audio features and spectrogram images.

ğŸ“ŒFeatures
Extracted Audio Features: MFCC, Chroma, Pitch, Intensity, Tempo, Zero-Crossing Rate Mean, Spectral Centroid Mean
Human Evaluation Scores: Volume, Pace, Tone, Pronunciation, Vocal Variety, Vocal Control, Fluency

ğŸ–¥ï¸Models Implemented:
Support Vector Machine (SVM)
Random Forest (RF)
Convolutional Neural Network (CNN)
YOLOv8 Classification

ğŸ“‚Dataset

CSV File: AudioScoreLatest.csv(Contains human evaluation scores), aggregated_results_mean.csv(Contains extracted audio features)

Spectrogram Images: .jpg files generated from audio samples.

ğŸ–‹ï¸Scores are categorized into three labels:
0 â†’ Bad (1â€“2)
1 â†’ Neutral/Good (3)
2 â†’ Very Good (4â€“5)
