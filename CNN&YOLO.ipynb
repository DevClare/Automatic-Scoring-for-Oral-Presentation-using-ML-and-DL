{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM38EsOtGuuV23idBrty6U6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DevClare/Automatic-Scoring-for-Oral-Presentation-using-ML-and-DL/blob/main/CNN%26YOLO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_fgxD-Dgw3kh",
        "outputId": "ec57be96-6937-477c-c6b2-93187701a3b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "CSV loaded. Shape: (72, 9)\n",
            "            Name  Volume  Pace  Tone  Pronounciation  Vocal Variety  \\\n",
            "0  AbdallahTamer       3     4     3               4              3   \n",
            "1      AlanTiong       5     3     1               4              2   \n",
            "2         Alsten       2     4     5               3              4   \n",
            "3    ArielAthomo       5     2     3               2              3   \n",
            "4      Avvinnesh       4     4     3               5              2   \n",
            "\n",
            "   Vocal Control  Fluency  Total  \n",
            "0              4        4    NaN  \n",
            "1              4        5    NaN  \n",
            "2              5        5    NaN  \n",
            "3              3        3    NaN  \n",
            "4              5        5    NaN  \n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Path to CSV file in the drive\n",
        "csv_path = \"/content/drive/MyDrive/Dataset/AudioScoreLatest.csv\"\n",
        "\n",
        "scores_df = pd.read_csv(csv_path)\n",
        "print(\"CSV loaded. Shape:\", scores_df.shape)\n",
        "print(scores_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "# Path to spectrogram images in drive\n",
        "image_folder = \"/content/drive/MyDrive/Dataset/spectrograms\" #ADJUST\n",
        "\n",
        "HUMAN_SCORE_COLUMNS = [\"Volume\",\"Pace\",\"Tone\",\"Pronounciation\",\"Vocal Variety\",\"Vocal Control\",\"Fluency\"]\n",
        "\n",
        "#Calculate average of human evaluated scores\n",
        "scores_df[\"AvgScore\"] = scores_df[HUMAN_SCORE_COLUMNS].mean(axis=1)\n",
        "\n",
        "# Map average to class, 0 = bad(average score of 1-2), 1 = neutral(average score of 2-3.5), 2 = very good(average score above 3.5)\n",
        "def map_score_to_class(s):\n",
        "    if s <= 2: return 0\n",
        "    elif 2 < s <= 3.5: return 1\n",
        "    else: return 2\n",
        "\n",
        "scores_df[\"Label\"] = scores_df[\"AvgScore\"].apply(map_score_to_class)\n",
        "\n",
        "# Prepare images + labels\n",
        "IMG_SIZE = 128\n",
        "image_data, labels = [], []\n",
        "\n",
        "for idx, row in tqdm(scores_df.iterrows(), total=len(scores_df)):\n",
        "    filename = row[\"Name\"] + \".jpg\"\n",
        "    filepath = os.path.join(image_folder, filename)\n",
        "    if os.path.exists(filepath):\n",
        "        img = cv2.imread(filepath, cv2.IMREAD_COLOR)\n",
        "        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
        "        image_data.append(img)\n",
        "        labels.append(row[\"Label\"])\n",
        "\n",
        "X = np.array(image_data) / 255.0\n",
        "y = to_categorical(np.array(labels), num_classes=3)\n",
        "\n",
        "# Train/test split, 80% for training, 20% for testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# CNN model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3,3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3)),\n",
        "    MaxPooling2D((2,2)),\n",
        "    Conv2D(64, (3,3), activation='relu'),\n",
        "    MaxPooling2D((2,2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(X_train, y_train, validation_split=0.2, epochs=10, batch_size=32)\n",
        "\n",
        "# Evaluate\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)\n",
        "print(f\"CNN Test Accuracy: {test_acc:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "fPCZym3qw_A4",
        "outputId": "f8c41e68-053e-408e-de1b-dbaada038447"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 72/72 [00:28<00:00,  2.52it/s]\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 446ms/step - accuracy: 0.4970 - loss: 1.1059 - val_accuracy: 0.5000 - val_loss: 3.6539\n",
            "Epoch 2/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 290ms/step - accuracy: 0.6632 - loss: 2.3710 - val_accuracy: 0.4167 - val_loss: 2.0442\n",
            "Epoch 3/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 272ms/step - accuracy: 0.5370 - loss: 1.3974 - val_accuracy: 0.5000 - val_loss: 1.3906\n",
            "Epoch 4/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 285ms/step - accuracy: 0.7241 - loss: 0.7433 - val_accuracy: 0.4167 - val_loss: 1.2567\n",
            "Epoch 5/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 412ms/step - accuracy: 0.7641 - loss: 0.6171 - val_accuracy: 0.4167 - val_loss: 1.0410\n",
            "Epoch 6/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 409ms/step - accuracy: 0.7729 - loss: 0.6430 - val_accuracy: 0.4167 - val_loss: 1.0334\n",
            "Epoch 7/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 287ms/step - accuracy: 0.8190 - loss: 0.5708 - val_accuracy: 0.3333 - val_loss: 1.3262\n",
            "Epoch 8/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 301ms/step - accuracy: 0.7433 - loss: 0.5595 - val_accuracy: 0.5000 - val_loss: 1.3774\n",
            "Epoch 9/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 302ms/step - accuracy: 0.8590 - loss: 0.4300 - val_accuracy: 0.4167 - val_loss: 1.3546\n",
            "Epoch 10/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 286ms/step - accuracy: 0.8338 - loss: 0.3741 - val_accuracy: 0.5000 - val_loss: 1.5666\n",
            "1/1 - 0s - 79ms/step - accuracy: 0.8000 - loss: 0.4707\n",
            "CNN Test Accuracy: 0.80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Make YOLO dataset dirs\n",
        "base_dir = \"/content/drive/MyDrive/YourFolder/yolo_dataset\"\n",
        "for split in [\"train\", \"val\"]:\n",
        "    for cls in [\"bad\", \"neutral_good\", \"very_good\"]:\n",
        "        os.makedirs(os.path.join(base_dir, split, cls), exist_ok=True)\n",
        "\n",
        "# Split filenames\n",
        "train_files, val_files = train_test_split(scores_df, test_size=0.2, random_state=42, stratify=scores_df[\"Label\"])\n",
        "\n",
        "# Helper to map label -> class folder\n",
        "def label_to_class(lbl):\n",
        "    return \"bad\" if lbl == 0 else \"neutral_good\" if lbl == 1 else \"very_good\"\n",
        "\n",
        "# Copy images to YOLO dataset\n",
        "def copy_files(file_list, split):\n",
        "    for _, row in tqdm(file_list.iterrows(), total=len(file_list)):\n",
        "        filename = row[\"Name\"] + \".jpg\"\n",
        "        src = os.path.join(image_folder, filename)\n",
        "        if os.path.exists(src):\n",
        "            cls = label_to_class(row[\"Label\"])\n",
        "            dst = os.path.join(base_dir, split, cls, filename)\n",
        "            shutil.copy(src, dst)\n",
        "\n",
        "copy_files(train_files, \"train\")\n",
        "copy_files(val_files, \"val\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yywhGkuExNQw",
        "outputId": "00cf6181-ed21-4b34-b253-9ddb021f9922"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 57/57 [00:00<00:00, 94.80it/s]\n",
            "100%|██████████| 15/15 [00:00<00:00, 96.95it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics\n",
        "\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Use pretrained YOLOv8 classification model\n",
        "model = YOLO(\"yolov8n-cls.pt\")\n",
        "\n",
        "# Train\n",
        "model.train(\n",
        "    data=base_dir,\n",
        "    epochs=20,\n",
        "    imgsz=128,\n",
        "    batch=32\n",
        ")\n",
        "\n",
        "# Validate\n",
        "metrics = model.val()\n",
        "print(\"YOLOv8 Top-1 Accuracy:\", metrics.top1)\n",
        "print(\"YOLOv8 Top-5 Accuracy:\", metrics.top5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "UBHcvpSy4WYe",
        "outputId": "6ab17a7d-2719-4fa1-ec7a-f1e399812fe1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.206-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.2)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.23.0+cu126)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: polars in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.25.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.17-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2025.8.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\n",
            "Downloading ultralytics-8.3.206-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.17-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.206 ultralytics-thop-2.0.17\n",
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n-cls.pt to 'yolov8n-cls.pt': 100% ━━━━━━━━━━━━ 5.3MB 62.6MB/s 0.1s\n",
            "Ultralytics 8.3.206 🚀 Python-3.12.11 torch-2.8.0+cu126 CPU (AMD EPYC 7B12)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/YourFolder/yolo_dataset, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=128, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n-cls.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/runs/classify/train, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=classify, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/drive/MyDrive/YourFolder/yolo_dataset/train... found 57 images in 3 classes ✅ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/drive/MyDrive/YourFolder/yolo_dataset/val... found 15 images in 3 classes ✅ \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
            "Overriding model.yaml nc=1000 with nc=3\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    334083  ultralytics.nn.modules.head.Classify         [256, 3]                      \n",
            "YOLOv8n-cls summary: 56 layers, 1,442,131 parameters, 1,442,131 gradients, 3.4 GFLOPs\n",
            "Transferred 156/158 items from pretrained weights\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.3±0.1 ms, read: 39.7±9.4 MB/s, size: 78.8 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/YourFolder/yolo_dataset/train... 57 images, 0 corrupt: 100% ━━━━━━━━━━━━ 57/57 141.4it/s 0.4s\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/drive/MyDrive/YourFolder/yolo_dataset/train.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.6±0.4 ms, read: 42.6±9.5 MB/s, size: 73.4 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/YourFolder/yolo_dataset/val... 15 images, 0 corrupt: 100% ━━━━━━━━━━━━ 15/15 232.2it/s 0.1s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/drive/MyDrive/YourFolder/yolo_dataset/val.cache\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
            "Image sizes 128 train, 128 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs/classify/train\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% ━━━━━━━━━━━━ 755.1KB 15.5MB/s 0.0s\n",
            "\u001b[K       1/20         0G      1.241         25        128: 100% ━━━━━━━━━━━━ 2/2 1.3it/s 1.5s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 1/1 4.4it/s 0.2s\n",
            "                   all      0.333          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K       2/20         0G      1.274         25        128: 100% ━━━━━━━━━━━━ 2/2 1.6it/s 1.2s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 1/1 4.3it/s 0.2s\n",
            "                   all      0.333          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K       3/20         0G       1.24         25        128: 100% ━━━━━━━━━━━━ 2/2 1.7it/s 1.2s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 1/1 4.7it/s 0.2s\n",
            "                   all      0.333          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K       4/20         0G      1.201         25        128: 100% ━━━━━━━━━━━━ 2/2 1.7it/s 1.2s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 1/1 4.9it/s 0.2s\n",
            "                   all      0.333          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K       5/20         0G      1.085         25        128: 100% ━━━━━━━━━━━━ 2/2 1.7it/s 1.2s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 1/1 4.8it/s 0.2s\n",
            "                   all      0.333          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K       6/20         0G     0.9997         25        128: 100% ━━━━━━━━━━━━ 2/2 1.7it/s 1.2s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 1/1 4.4it/s 0.2s\n",
            "                   all      0.467          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K       7/20         0G      1.008         25        128: 100% ━━━━━━━━━━━━ 2/2 1.1it/s 1.8s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 1/1 3.1it/s 0.3s\n",
            "                   all      0.733          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K       8/20         0G     0.8987         25        128: 100% ━━━━━━━━━━━━ 2/2 1.5it/s 1.3s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 1/1 4.9it/s 0.2s\n",
            "                   all      0.667          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K       9/20         0G     0.8452         25        128: 100% ━━━━━━━━━━━━ 2/2 1.7it/s 1.2s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 1/1 4.4it/s 0.2s\n",
            "                   all      0.867          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K      10/20         0G     0.8382         25        128: 100% ━━━━━━━━━━━━ 2/2 1.6it/s 1.2s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 1/1 4.4it/s 0.2s\n",
            "                   all      0.867          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K      11/20         0G     0.7973         25        128: 100% ━━━━━━━━━━━━ 2/2 1.7it/s 1.2s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 1/1 4.8it/s 0.2s\n",
            "                   all        0.8          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K      12/20         0G      0.776         25        128: 100% ━━━━━━━━━━━━ 2/2 1.7it/s 1.2s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 1/1 5.1it/s 0.2s\n",
            "                   all      0.733          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K      13/20         0G     0.7221         25        128: 100% ━━━━━━━━━━━━ 2/2 1.6it/s 1.2s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 1/1 4.7it/s 0.2s\n",
            "                   all      0.733          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K      14/20         0G     0.7297         25        128: 100% ━━━━━━━━━━━━ 2/2 1.4it/s 1.4s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 1/1 4.0it/s 0.2s\n",
            "                   all        0.8          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K      15/20         0G     0.6562         25        128: 100% ━━━━━━━━━━━━ 2/2 1.5it/s 1.3s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 1/1 4.6it/s 0.2s\n",
            "                   all        0.8          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K      16/20         0G     0.6538         25        128: 100% ━━━━━━━━━━━━ 2/2 1.6it/s 1.2s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 1/1 4.7it/s 0.2s\n",
            "                   all        0.8          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K      17/20         0G     0.6364         25        128: 100% ━━━━━━━━━━━━ 2/2 1.7it/s 1.2s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 1/1 4.5it/s 0.2s\n",
            "                   all        0.8          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K      18/20         0G     0.6403         25        128: 100% ━━━━━━━━━━━━ 2/2 1.7it/s 1.2s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 1/1 4.9it/s 0.2s\n",
            "                   all        0.8          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K      19/20         0G     0.6702         25        128: 100% ━━━━━━━━━━━━ 2/2 1.6it/s 1.2s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 1/1 4.8it/s 0.2s\n",
            "                   all        0.8          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K      20/20         0G      0.627         25        128: 100% ━━━━━━━━━━━━ 2/2 1.7it/s 1.2s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 1/1 5.2it/s 0.2s\n",
            "                   all        0.8          1\n",
            "\n",
            "20 epochs completed in 0.009 hours.\n",
            "Optimizer stripped from /content/runs/classify/train/weights/last.pt, 3.0MB\n",
            "Optimizer stripped from /content/runs/classify/train/weights/best.pt, 3.0MB\n",
            "\n",
            "Validating /content/runs/classify/train/weights/best.pt...\n",
            "Ultralytics 8.3.206 🚀 Python-3.12.11 torch-2.8.0+cu126 CPU (AMD EPYC 7B12)\n",
            "YOLOv8n-cls summary (fused): 30 layers, 1,438,723 parameters, 0 gradients, 3.3 GFLOPs\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/drive/MyDrive/YourFolder/yolo_dataset/train... found 57 images in 3 classes ✅ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/drive/MyDrive/YourFolder/yolo_dataset/val... found 15 images in 3 classes ✅ \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 1/1 4.9it/s 0.2s\n",
            "                   all      0.867          1\n",
            "Speed: 0.0ms preprocess, 2.9ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/classify/train\u001b[0m\n",
            "Ultralytics 8.3.206 🚀 Python-3.12.11 torch-2.8.0+cu126 CPU (AMD EPYC 7B12)\n",
            "YOLOv8n-cls summary (fused): 30 layers, 1,438,723 parameters, 0 gradients, 3.3 GFLOPs\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/drive/MyDrive/YourFolder/yolo_dataset/train... found 57 images in 3 classes ✅ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/drive/MyDrive/YourFolder/yolo_dataset/val... found 15 images in 3 classes ✅ \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.4±0.1 ms, read: 29.6±10.6 MB/s, size: 73.4 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/YourFolder/yolo_dataset/val... 15 images, 0 corrupt: 100% ━━━━━━━━━━━━ 15/15 16.2Kit/s 0.0s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 1/1 3.9it/s 0.3s\n",
            "                   all      0.867          1\n",
            "Speed: 0.0ms preprocess, 3.7ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/classify/val\u001b[0m\n",
            "YOLOv8 Top-1 Accuracy: 0.8666666746139526\n",
            "YOLOv8 Top-5 Accuracy: 1.0\n"
          ]
        }
      ]
    }
  ]
}